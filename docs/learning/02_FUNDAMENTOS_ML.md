# ğŸ§  Fundamentos de Machine Learning

## Â¿QuÃ© es Machine Learning?

**Machine Learning (ML)** es una rama de la Inteligencia Artificial que permite a las computadoras **aprender de datos** sin ser programadas explÃ­citamente para cada tarea.

### AnalogÃ­a Simple
Imagina que quieres enseÃ±ar a alguien a reconocer si un equipo va a ganar:

- **ProgramaciÃ³n tradicional**: Escribes reglas como "si el equipo local ganÃ³ los Ãºltimos 3 partidos Y el visitante perdiÃ³ 2, entonces gana el local"
- **Machine Learning**: Le das miles de ejemplos de partidos pasados con sus resultados, y el algoritmo descubre las reglas por sÃ­ mismo

---

## ğŸ“š Tipos de Machine Learning

### 1. ğŸ¯ Aprendizaje Supervisado (Supervised Learning)
**Es lo que usa este proyecto.**

- Tienes **datos etiquetados**: sabes el resultado real de cada partido histÃ³rico
- El modelo aprende la relaciÃ³n entre **inputs (features)** y **outputs (targets)**

```
Features (X)                          Target (y)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Forma local: 2.5                      
Forma visitante: 1.8          â†’       Home Win âœ“
Goles prom local: 1.8
Goles prom visitante: 1.2
```

**Ejemplos en el proyecto:**
- ClasificaciÃ³n de resultado (Home/Draw/Away)
- PredicciÃ³n de goles totales
- BTTS (ambos anotan)

### 2. ğŸ” Aprendizaje No Supervisado (Unsupervised Learning)
- No hay etiquetas/respuestas correctas
- El modelo encuentra **patrones ocultos**
- Ejemplo: agrupar equipos por estilo de juego

### 3. ğŸ® Aprendizaje por Refuerzo (Reinforcement Learning)
- Un agente aprende por **prueba y error**
- Recibe recompensas/castigos
- Ejemplo: IA jugando videojuegos

---

## ğŸ¯ ClasificaciÃ³n vs RegresiÃ³n

Este proyecto usa **ambos tipos**:

### ClasificaciÃ³n
Predecir una **categorÃ­a/clase** discreta.

```python
# En el proyecto (predictor.py)
# Target: resultado del partido
result_map = {'A': 0, 'D': 1, 'H': 2}  # Clases: Away, Draw, Home

# El modelo responde: "Este partido serÃ¡ Home Win"
# Con probabilidades: Home 58%, Draw 27%, Away 15%
```

**Usos en el proyecto:**
- Resultado 1X2 (3 clases)
- BTTS SÃ­/No (2 clases - clasificaciÃ³n binaria)

### RegresiÃ³n
Predecir un **valor numÃ©rico** continuo.

```python
# En el proyecto
# Target: goles totales
y_goals = df['FullTimeHomeGoals'] + df['FullTimeAwayGoals']

# El modelo responde: "HabrÃ¡ aproximadamente 2.7 goles"
```

**Usos en el proyecto:**
- PredicciÃ³n de goles totales

---

## ğŸ“Š DivisiÃ³n de Datos: Train/Test Split

### Â¿Por quÃ© dividir los datos?

Para evaluar si el modelo realmente **generaliza** o solo memoriza.

```
Dataset Total (8000 partidos)
â”œâ”€â”€ 80% Train (6400 partidos) â†’ Para ENTRENAR el modelo
â””â”€â”€ 20% Test (1600 partidos)  â†’ Para EVALUAR el modelo
```

### âš ï¸ Importante: DivisiÃ³n Temporal

En series de tiempo (como partidos de fÃºtbol), **NO debemos mezclar aleatoriamente**. Usamos **divisiÃ³n temporal**:

```python
# De feature_engineering.py
# Split temporal (no aleatorio para series de tiempo)
split_idx = int(len(X_filled) * (1 - test_size))

X_train = X_filled[:split_idx]   # Partidos mÃ¡s antiguos
X_test = X_filled[split_idx:]    # Partidos mÃ¡s recientes
```

**Â¿Por quÃ©?** No queremos que el modelo "vea el futuro" durante el entrenamiento. Si mezclamos, podrÃ­a aprender de un partido de 2024 para predecir uno de 2020.

---

## ğŸ“ MÃ©tricas de EvaluaciÃ³n

### Para ClasificaciÃ³n

#### Accuracy (PrecisiÃ³n)
```
Accuracy = Predicciones Correctas / Total de Predicciones

Ejemplo: Si de 100 partidos predijimos 55 correctamente:
Accuracy = 55/100 = 55%
```

#### Confusion Matrix (Matriz de ConfusiÃ³n)
```
                    PredicciÃ³n
                    Away  Draw  Home
              Away   15    8     7     (30 partidos Away reales)
Realidad      Draw   10   12    13     (35 partidos Draw reales)
              Home    5   10    20     (35 partidos Home reales)
```

### Para RegresiÃ³n

#### MAE (Mean Absolute Error)
```
MAE = Promedio de |Real - PredicciÃ³n|

Si predicciÃ³n = 2.5 goles y real = 3 goles:
Error = |3 - 2.5| = 0.5

MAE bajo = mejor modelo
```

En el proyecto, el mejor modelo de goles tiene **MAE = 0.84** (se equivoca en promedio por 0.84 goles).

---

## ğŸ”„ El Flujo de Entrenamiento

```
1. CARGAR DATOS
   df = pd.read_csv('epl_final.csv')

2. FEATURE ENGINEERING
   X, y = engineer_features(df)

3. DIVIDIR DATOS
   X_train, X_test, y_train, y_test = train_test_split(X, y)

4. NORMALIZAR (SCALING)
   scaler = StandardScaler()
   X_train_scaled = scaler.fit_transform(X_train)
   X_test_scaled = scaler.transform(X_test)

5. ENTRENAR MODELO
   model = RandomForestClassifier()
   model.fit(X_train_scaled, y_train)

6. EVALUAR
   predictions = model.predict(X_test_scaled)
   accuracy = accuracy_score(y_test, predictions)

7. GUARDAR MODELO
   pickle.dump(model, open('model.pkl', 'wb'))
```

---

## ğŸ›ï¸ HiperparÃ¡metros

Son **configuraciones** del algoritmo que debemos establecer **antes** del entrenamiento:

```python
# Ejemplo de hiperparÃ¡metros en Random Forest
RandomForestClassifier(
    n_estimators=200,      # NÃºmero de Ã¡rboles
    max_depth=10,          # Profundidad mÃ¡xima de cada Ã¡rbol
    min_samples_split=5,   # MÃ­nimo de muestras para dividir un nodo
    random_state=42        # Semilla para reproducibilidad
)
```

### Â¿CÃ³mo encontrar los mejores?

- **Grid Search**: Probar todas las combinaciones
- **Random Search**: Probar combinaciones aleatorias
- **Cross-Validation**: Validar en mÃºltiples splits

---

## âš ï¸ Problemas Comunes

### Overfitting (Sobreajuste)
El modelo **memoriza** los datos de entrenamiento pero no generaliza.

```
Train Accuracy: 95%  â† Â¡Muy bien en entrenamiento!
Test Accuracy: 52%   â† Pero mal en datos nuevos ğŸ˜¢
```

**Soluciones:**
- MÃ¡s datos de entrenamiento
- Simplificar el modelo (menos profundidad, menos features)
- RegularizaciÃ³n
- Cross-validation

### Underfitting (Subajuste)
El modelo es **demasiado simple** y no captura los patrones.

```
Train Accuracy: 40%  â† Mal incluso en entrenamiento
Test Accuracy: 38%   â† Y mal en test tambiÃ©n
```

**Soluciones:**
- Modelo mÃ¡s complejo
- MÃ¡s features
- Menos regularizaciÃ³n

### Data Leakage (Fuga de Datos)
Cuando el modelo tiene acceso a informaciÃ³n que **no tendrÃ­a en producciÃ³n**.

**Ejemplo en fÃºtbol:**
Si incluyes los tiros a puerta del partido como feature para predecir el resultado... Â¡el modelo tendrÃ¡ 99% accuracy porque esa informaciÃ³n ya revela el resultado! Pero en un partido futuro, no tienes esos datos antes de que ocurra.

---

## ğŸ’¡ Conceptos Clave en el Proyecto

### Probabilidades de PredicciÃ³n
Los modelos no solo dicen "Home Win", sino que dan **probabilidades**:

```python
# De predictor.py
prob_result_rf = self.rf_result.predict_proba(X_new_scaled)[0]
# Resultado: [0.15, 0.27, 0.58] â†’ Away 15%, Draw 27%, Home 58%
```

### Confianza del Modelo
La **mÃ¡xima probabilidad** indica quÃ© tan seguro estÃ¡ el modelo:

```python
# Si las probabilidades son [0.15, 0.27, 0.58]:
confianza = max([0.15, 0.27, 0.58]) * 100  # = 58%

# Si fueran [0.33, 0.34, 0.33]:
confianza = 34%  # â† Modelo muy inseguro
```

---

## ğŸš€ Siguiente Paso

ContinÃºa con [03_LIBRERIAS_ML_PYTHON.md](03_LIBRERIAS_ML_PYTHON.md) para conocer las librerÃ­as que hacen posible todo esto.
