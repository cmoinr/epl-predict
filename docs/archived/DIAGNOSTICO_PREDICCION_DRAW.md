# ğŸ”´ DIAGNÃ“STICO: Â¿Por quÃ© el modelo predice demasiados "Draw"?

## 1. LA REALIDAD DE TUS DATOS

```
Tu Dataset HistÃ³rico (9,410 partidos):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resultado               â”‚ Cantidad â”‚ % Total â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ  Home Win (1)         â”‚  4,310   â”‚ 45.80%  â”‚
â”‚ ğŸ¤ Draw (X)             â”‚  2,318   â”‚ 24.63%  â”‚
â”‚ ğŸš— Away Win (2)         â”‚  2,782   â”‚ 29.56%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’¡ Esperado en fÃºtbol real: ~45% / ~27% / ~28%
âš ï¸  TU DATASET: ~46% / ~24.6% / ~29.6%  âœ“ ESTÃ BIEN DISTRIBUIDO
```

## 2. EL VERDADERO PROBLEMA: SESGO DE CLASE EN EL MODELO

El modelo NO tiene sesgo en los **datos**, tiene sesgo en cÃ³mo **entrena**.

### ğŸ¤” Â¿QuÃ© estÃ¡ pasando?

**Caso real de tu modelo:**
```
PredicciÃ³n Chelsea vs Liverpool:

Random Forest:
  - Confianza: 37% (INDECISO)
  - Probabilidades: Away 33% | Draw 37% | Home 30%

Gradient Boosting:
  - Confianza: 84.5% (MUY SEGURO)
  - Probabilidades: Away 7.6% | Draw 84.5% | Home 7.9%
```

**Â¿Por quÃ© Gradient Boosting predice 84.5% Draw?**

Es porque durante el entrenamiento, el modelo encontrÃ³ un patrÃ³n que **coincide accidentalmente** con empates. No es que "piense que habrÃ¡ empate", es que sus features (caracterÃ­sticas) generan valores que el modelo aprendiÃ³ a asociar con empates.

### ğŸ“Š La realidad de los goles

| Resultado | Promedio Goles | 
|-----------|---|
| Home Win | 2.99 goles |
| **Draw** | **2.01 goles** â¬…ï¸ MENOS goles |
| Away Win | 2.88 goles |

**Descubrimiento:** Los EMPATES tienen **MENOS goles totales** (2.01 vs 2.99)

Esto significa que:
- Partidos con pocas oportunidades â†’ Tiende a empate
- Partidos con muchas oportunidades â†’ Tiende a victoria clara

**Tu modelo estÃ¡ viendo:**
```
Features bajos (poco ofensivos) â†’ Predice Draw
```

Pero esto es INCORRECTO cuando:
- Chelsea juega contra Liverpool (claro favorito a victoria)
- Hay gran diferencia en posiciÃ³n de tabla

---

## 3. SOLUCIONES CONCRETAS

### âœ… SOLUCIÃ“N 1: Balancear clases en el entrenamiento

**Problema:** El modelo ve 45% home wins vs 24% draws
- Aprende a ser conservador con draws (son mÃ¡s raros)
- Pero cuando ve features "ambiguas", elige draw por defecto

**SoluciÃ³n:** Usar `class_weight='balanced'`

```python
# EN: src/models.py

# Random Forest
rf_result = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    min_samples_leaf=2,
    class_weight='balanced',  # â† AGREGAR ESTO
    random_state=42,
    n_jobs=-1
)

# Gradient Boosting
gb_result = GradientBoostingClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    min_samples_split=5,
    min_samples_leaf=2,
    class_weight='balanced',  # â† AGREGAR ESTO
    random_state=42
)
```

---

### âœ… SOLUCIÃ“N 2: Mejorar las caracterÃ­sticas (Features)

**El problema real:** Tus features NO capturan bien "quiÃ©n es favorito"

Features actuales en `predictor.py`:
```
- HomeTeam_Form (Ãºltimos 5 partidos)
- AwayTeam_Form (Ãºltimos 5 partidos)
- H2H_HomeTeamWins
- Goals For/Against (media)
- Mes y dÃ­a de la semana
- HomeAdvantage (constante 0.3)
```

**Lo que FALTA:**
```python
# AGREGAR ESTAS CARACTERÃSTICAS:

1. Diferencia en posiciÃ³n de tabla (ranking)
   Chelsea 6Âº vs Liverpool 8Âº â†’ diferencia = -2 (Liverpool es mejor)
   
2. Diferencia en goles anotados este aÃ±o
   Chelsea 45 goles vs Liverpool 52 goles â†’ diferencia = -7
   
3. Racha actual (Ãºltimos 3 partidos, no 5)
   Si ganÃ³ 2 de 3: forma = 0.67
   
4. Ventaja en casa mejorada (basada en datos)
   Home win rate: 50% en casa vs 30% fuera
   
5. Factor de "fuerza relativa"
   (Puntos Chelsea - Puntos Liverpool) / 10
```

---

### âœ… SOLUCIÃ“N 3: Ajustar los hiperparÃ¡metros

**Problema:** Los parÃ¡metros actuales son "seguros" pero blandos

```python
# ACTUAL (muy conservador):
max_depth=15,              # Permite muchas divisiones
min_samples_split=5,       # Solo requiere 5 muestras para dividir
min_samples_leaf=2         # Hojas muy pequeÃ±as

# MEJORADO (menos overfitting, mÃ¡s decisiones claras):
max_depth=10,              # Reduce complejidad
min_samples_split=10,      # Requiere mÃ¡s muestras
min_samples_leaf=5         # Hojas mÃ¡s grandes
max_features='sqrt',       # Usa sqrt(n_features) en cada divisiÃ³n
```

---

### âœ… SOLUCIÃ“N 4: Usar probabilidades calibradas

**Problema:** Las probabilidades del modelo NO son reales

```
Random Forest: 37% Draw
Gradient Boosting: 84.5% Draw

Â¿Significa que hay 37% o 84.5% de probabilidad real? NO.
El modelo estÃ¡ "adivinando" sin calibraciÃ³n.
```

**SoluciÃ³n:** Usar `CalibratedClassifierCV`

```python
from sklearn.calibration import CalibratedClassifierCV

# DespuÃ©s de entrenar el modelo:
rf_result_calibrated = CalibratedClassifierCV(
    rf_result, 
    method='sigmoid',
    cv=5
)
rf_result_calibrated.fit(X_train, y_result_train)

# Ahora las probabilidades son REALES
prob_calibrated = rf_result_calibrated.predict_proba(X_new)
```

---

## 4. PLAN DE ACCIÃ“N PRIORITARIO

### Paso 1: QUICK FIX (5 minutos)
```
âœ… Agregar class_weight='balanced' a ambos modelos
âœ… Reentrenar
âœ… Probar predicciones
```

### Paso 2: MEJORA MEDIANA (30 minutos)
```
âœ… Mejorar features: agregar diferencia de tabla + goles anotados
âœ… Reentrenar
âœ… Probar
```

### Paso 3: MEJORA AVANZADA (1 hora)
```
âœ… Calibrar probabilidades
âœ… Ajustar hiperparÃ¡metros
âœ… Validation cruzada
âœ… Comparar modelos
```

---

## 5. EJEMPLO: ANTES vs DESPUÃ‰S

### ANTES (Actual):
```
Chelsea vs Liverpool
Random Forest: Draw (37%)
Gradient Boosting: Draw (84.5%)
```

### DESPUÃ‰S (Esperado con mejoras):
```
Chelsea vs Liverpool
Random Forest: Home Win (52%)
Gradient Boosting: Home Win (68%)

Promedio de confianza: 60%
```

---

## 6. Â¿CUÃL ES LA CAUSA ROOT?

**Tu modelo estÃ¡ tratando todos los partidos igual:**

```
Entrada: Features genÃ©ricas
  â†“
Modelo: "No veo diferencia clara entre equipos"
  â†“
Salida: "Entonces debe ser Draw" (default seguro)
```

**Lo que deberÃ­a hacer:**

```
Entrada: Chelsea 6Âº tabla, Liverpool 8Âº tabla, Chelsea 45 goles, Liverpool 52
  â†“
Modelo: "Hay ligera ventaja para Liverpool pero margen pequeÃ±o"
  â†“
Salida: "Liverpool ganarÃ¡ con 65% de confianza, Chelsea 30%, Draw 5%"
```

---

## 7. RECOMENDACIÃ“N FINAL

1. **Comienza por SoluciÃ³n 1** (class_weight) - impacto inmediato
2. **Luego SoluciÃ³n 2** (features mejores) - impacto mayor
3. **DespuÃ©s SoluciÃ³n 3** (hiperparÃ¡metros) - fine tuning
4. **Finalmente SoluciÃ³n 4** (calibraciÃ³n) - robustez

El problema NO es tu dataset, es que el modelo necesita **aprender a diferenciar mejor entre equipos**.

