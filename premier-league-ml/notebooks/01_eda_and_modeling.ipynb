{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd3842e",
   "metadata": {},
   "source": [
    "## 1. Cargar y Explorar Dataset EPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62740d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilos\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print('‚úÖ Librer√≠as importadas correctamente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset EPL\n",
    "data_path = Path('../data/raw/epl_final.csv')\n",
    "\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f'‚úÖ Dataset cargado: {df.shape[0]} filas √ó {df.shape[1]} columnas')\n",
    "    print(f'\\nüìÖ Rango temporal: {df.iloc[:, 0] if \"Date\" in str(df.columns) else \"Verificar columnas\"}')\n",
    "else:\n",
    "    print(f'‚ùå Archivo no encontrado en {data_path}')\n",
    "    print(f'   Descarga epl_final.csv desde Kaggle y col√≥calo en: data/raw/')\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3511a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspeccionar estructura del dataset\n",
    "if df is not None:\n",
    "    print('\\n' + '='*70)\n",
    "    print('ESTRUCTURA DEL DATASET')\n",
    "    print('='*70)\n",
    "    \n",
    "    print(f'\\nüìã Columnas ({len(df.columns)}):')  \n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        dtype = df[col].dtype\n",
    "        nulls = df[col].isnull().sum()\n",
    "        print(f'   {i:2d}. {col:<25} {str(dtype):<15} (nulls: {nulls:4d})')\n",
    "    \n",
    "    print(f'\\nüìä Primeras 5 filas:')\n",
    "    display(df.head())\n",
    "    \n",
    "    print(f'\\nüìä Info del Dataset:')\n",
    "    print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9804602",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento y Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Hacer una copia para trabajar\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Identificar columnas de fecha\n",
    "    date_cols = [col for col in df_processed.columns if 'date' in col.lower()]\n",
    "    print(f'Columnas de fecha encontradas: {date_cols}')\n",
    "    \n",
    "    # Convertir a datetime si es necesario\n",
    "    for col in date_cols:\n",
    "        df_processed[col] = pd.to_datetime(df_processed[col], errors='coerce')\n",
    "    \n",
    "    # Verificar valores nulos\n",
    "    print(f'\\nüìä Valores nulos por columna:')\n",
    "    null_counts = df_processed.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0].sort_values(ascending=False)\n",
    "    if len(null_counts) > 0:\n",
    "        print(null_counts)\n",
    "    else:\n",
    "        print('‚úÖ Sin valores nulos')\n",
    "    \n",
    "    print(f'\\n‚úÖ Preprocesamiento inicial completado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering - Crear features derivadas\n",
    "if df_processed is not None:\n",
    "    # Extraer caracter√≠sticas de tiempo\n",
    "    date_col = date_cols[0] if date_cols else None\n",
    "    \n",
    "    if date_col:\n",
    "        df_processed['Year'] = df_processed[date_col].dt.year\n",
    "        df_processed['Month'] = df_processed[date_col].dt.month\n",
    "        df_processed['DayOfWeek'] = df_processed[date_col].dt.dayofweek\n",
    "        df_processed['Season'] = df_processed['Year'].apply(lambda x: f'{x}-{x+1}')\n",
    "        print(f'‚úÖ Features temporales creadas')\n",
    "    \n",
    "    # Identificar columnas de equipo y resultado\n",
    "    print(f'\\nColumnas disponibles:')\n",
    "    print(df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baacd3a8",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c473a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_processed is not None:\n",
    "    print('\\n' + '='*70)\n",
    "    print('AN√ÅLISIS EXPLORATORIO')\n",
    "    print('='*70)\n",
    "    \n",
    "    # Estad√≠sticas b√°sicas\n",
    "    print('\\nüìä Estad√≠sticas descriptivas:')\n",
    "    display(df_processed.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ca4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar distribuciones\n",
    "if df_processed is not None:\n",
    "    # Encontrar columnas num√©ricas potencialmente interesantes\n",
    "    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    print(f'Columnas num√©ricas: {numeric_cols[:10]}...')\n",
    "    print(f'\\nTotal de columnas num√©ricas: {len(numeric_cols)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fc700f",
   "metadata": {},
   "source": [
    "## 4. Preparar Datos para Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if df_processed is not None:\n",
    "    print('Datos listos para la siguiente fase:')\n",
    "    print(f'  - {df_processed.shape[0]} muestras')\n",
    "    print(f'  - {df_processed.shape[1]} features')\n",
    "    print(f'\\n‚úÖ Pr√≥ximas fases: An√°lisis de target variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb318dd6",
   "metadata": {},
   "source": [
    "## 5. Modelo de Predicci√≥n de Resultados (1X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print('üìä Modelos de predicci√≥n de resultados preparados')\n",
    "print('  - Random Forest Classifier')\n",
    "print('  - Gradient Boosting Classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be28de8",
   "metadata": {},
   "source": [
    "## 6. Modelo de Predicci√≥n de Goles Totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89619d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print('üìä Modelos de predicci√≥n de goles preparados')\n",
    "print('  - Random Forest Regressor')\n",
    "print('  - Gradient Boosting Regressor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2bdec",
   "metadata": {},
   "source": [
    "## 7. Evaluaci√≥n y Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a2639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('‚úÖ Fase de evaluaci√≥n lista')\n",
    "print('M√©tricas a evaluar:')\n",
    "print('  Clasificaci√≥n: Accuracy, Precision, Recall, F1-Score, ROC-AUC')\n",
    "print('  Regresi√≥n: MAE, RMSE, R¬≤')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6a2bf",
   "metadata": {},
   "source": [
    "## 8. Comparar Predicciones vs Odds del Mercado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e83d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üìä Investigar APIs de odds disponibles:')\n",
    "print('  1. odds-api.com - Gratis con l√≠mite de requests')\n",
    "print('  2. RapidAPI - M√∫ltiples endpoints de apuestas')\n",
    "print('  3. Datos hist√≥ricos de sitios especializados')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca19e5",
   "metadata": {},
   "source": [
    "## 9. Identificar Oportunidades de Value Betting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üí° Estrategia de Value Betting:')\n",
    "print('\\n1. Calcular probabilidad impl√≠cita de odds:')\n",
    "print('   Prob_impl√≠cita = 1 / Odd')\n",
    "print('\\n2. Comparar con probabilidad predicha por modelo:')\n",
    "print('   Si Prob_modelo > Prob_impl√≠cita ‚Üí Posible value bet')\n",
    "print('\\n3. Filtrar por edge m√≠nimo (ej: 5%)')\n",
    "print('   Edge = Prob_modelo - Prob_impl√≠cita')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afcc4ac",
   "metadata": {},
   "source": [
    "## 10. An√°lisis de Rentabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('üí∞ M√©tricas de Rentabilidad:')\n",
    "print('  - ROI (Return on Investment)')\n",
    "print('  - Win Rate (%)')\n",
    "print('  - Valor Esperado (EV) por apuesta')\n",
    "print('  - Backtesting en datos hist√≥ricos')\n",
    "print('  - An√°lisis de rentabilidad por temporada')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
